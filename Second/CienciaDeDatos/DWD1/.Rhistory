U <- -U
U
a
U
res.cc
V
U
U[1,1]
U[,1]
U[,1]/sum((U[,1]**2)**.5
)
U[,1]/sum((U[,1]**2))**.5
sum((U[,1]**2))**.5
sum((U[1,]**2))**.5
res.cc$xcoef
res.cc$xcoef[,1]
sum(res.cc$xcoef[,1]**2)**.5
res.cc$xcoef
U
14/.03
U*466
.14/.03
U*4.6
U
res.cc$xcoef*4.6
correlaciones.canonicas
a
correlaciones.canonicas
res.cc
######NOTA: NOTAR EL TRASPUESTO => los resultados se leen por reglon
#t(U)%*% S11
### correlaciones de los pares canonicos con el segundo conjunto
#t(V)%*% S22
########### correlaciones del primer componente de los pares con el perimer grupo
#t(U)%*%S12
#########correlciones de la segunda componente canonica con el segundo grupo de variables
#t(V)%*%t(S12)
####################aPROXIMACIONES usando ambos pares
#sum(correlaciones.canonicas) #no podemos esperar mucho
A <- t(U) #para unificar notacion
A <- solve(A)
B <- t(V)
B <- solve(B)
i <- 1:2 #pares canonicos a usar
S11.aprox <-  S11 - (A[,i] %*% t(A[, i]))
S22.aprox <-  S22 - (B[,i] %*% t(B[, i]))
S12.aprox <-  S12 - (correlaciones.canonicas[i]* (A[,i] %*% t(B[, i]))) #con la primera, ATENCION CON EL INDICE DE correlacion del par acnonico
propo.S11 <- sum(diag(S11 -S11.aprox))/sum(diag(S11))
propo.S22 <- sum(diag(S11 -S22.aprox))/sum(diag(S22))
n <- 50 ##supongamos un tamanio de muestra
estadistico <- -n*log(prod(1-correlaciones.canonicas[i]**2))
valor.critico <- pchisq(1-.05, p*q)
ifelse(estadistico > valor.critico, 'Rechaza H0', 'No se rechaza H0')
valor.critico
res.cc
F.test.cca(cca.fit)
res.cc
i <- 1 #pares canonicos a usar
S11.aprox <-  S11 - (A[,i] %*% t(A[, i]))
S22.aprox <-  S22 - (B[,i] %*% t(B[, i]))
S12.aprox <-  S12 - (correlaciones.canonicas[i]* (A[,i] %*% t(B[, i]))) #con la primera, ATENCION CON EL INDICE DE correlacion del par acnonico
propo.S11 <- sum(diag(S11 -S11.aprox))/sum(diag(S11))
propo.S22 <- sum(diag(S11 -S22.aprox))/sum(diag(S22))
n <- 50 ##supongamos un tamanio de muestra
estadistico <- -n*log(prod(1-correlaciones.canonicas[i]**2))
valor.critico <- pchisq(1-.05, p*q)
ifelse(estadistico > valor.critico, 'Rechaza H0', 'No se rechaza H0')
i <- 1:2 #pares canonicos a usar
S11.aprox <-  S11 - (A[,i] %*% t(A[, i]))
S22.aprox <-  S22 - (B[,i] %*% t(B[, i]))
S12.aprox <-  S12 - (correlaciones.canonicas[i]* (A[,i] %*% t(B[, i]))) #con la primera, ATENCION CON EL INDICE DE correlacion del par acnonico
propo.S11 <- sum(diag(S11 -S11.aprox))/sum(diag(S11))
propo.S22 <- sum(diag(S11 -S22.aprox))/sum(diag(S22))
n <- 50 ##supongamos un tamanio de muestra
estadistico <- -n*log(prod(1-correlaciones.canonicas[i]**2))
valor.critico <- pchisq(1-.05, p*q)
ifelse(estadistico > valor.critico, 'Rechaza H0', 'No se rechaza H0')
library(smacof)
ratings <- 11-RockHard[,5:18]
rownames(ratings) <- RockHard[,"Band"]
fit.rock <- unfolding(ratings)
fit.rock
plot(fit.rock, label.conf.rows = list(label = TRUE))
plot(fit.rock, label.conf.rows = list(label =FALSE))
?unfolding
plot(fit.rock, label.conf.rows = list(label =FALSE), circle = c( "column"))
library(smacof)
ratings <- 11-RockHard[,5:18]
rownames(ratings) <- RockHard[,"Band"]
fit.rock <- unfolding(ratings, circle = c( "column"))
fit.rock
library(smacof)
ratings <- 11-RockHard[,5:18]
rownames(ratings) <- RockHard[,"Band"]
fit.rock <- unfolding(ratings, circle = c( "column"))
fit.rock
plot(fit.rock, label.conf.rows = list(label =FALSE), )
library(smacof)
ratings <- 11-RockHard[,5:18]
rownames(ratings) <- RockHard[,"Band"]
fit.rock <- unfolding(ratings, circle = c( "column"))
library(smacof)
ratings <- 11-RockHard[,5:18]
rownames(ratings) <- RockHard[,"Band"]
fit.rock <- unfolding(ratings, circle = c( "column"))
fit.rock <- unfolding(ratings, circle = c( "row"))
library(smacof)
ratings <- 11-RockHard[,5:18]
rownames(ratings) <- RockHard[,"Band"]
fit.rock <- unfolding(ratings, circle = c( "row"))
fit.rock
fit.rock <- unfolding(ratings, circle = c( "none"))
plot(fit.rock, label.conf.rows = list(label =FALSE), )
plot(p, 'Shepard', label.conf.rows = list(label =FALSE))
plot(fit.rock, 'Shepard', label.conf.rows = list(label =FALSE))
plot(fit.rock, "stressplot", label.conf.rows = list(label =FALSE))
plot(fit.rock, 'Shepard')
ratings <- 11-RockHard[,5:18]
rownames(ratings) <- RockHard[,"Band"]
fit.rock <- unfolding(ratings, circle = c( "none"), ndim= 7)
fit.rock
plot(fit.rock, label.conf.rows = list(label =FALSE) )
fit.rock <- unfolding(ratings, circle = c( "none"), ndim= 2)
fit.rock
fit.rock <- unfolding(ratings, circle = c( "none"), ndim= 7)
fit.rock
plot(fit.rock, label.conf.rows = list(label =FALSE) )
plot(fit.rock, 'Shepard')
plot(fit.rock, "stressplot", label.conf.rows = list(label =FALSE))
fit.rock <- unfolding(ratings, circle = c( "none"), ndim= 10)
fit.rock
plot(fit.rock, label.conf.rows = list(label =FALSE) )
plot(fit.rock, 'Shepard')
plot(fit.rock, "stressplot", label.conf.rows = list(label =FALSE))
best <- sort(rowMeans(ratings, na.rm = TRUE))[1:10]
worst <- sort(rowMeans(ratings, na.rm = TRUE), decreasing = TRUE)[1:10]
bestworst <- names(c(best, worst))
text(fit.rock$conf.row[bestworst,], labels = bestworst, cex = 0.8, pos = 3,
col = hcl(0, l = 50))
LawlerD <- sim2diss(Lawler)
fit.lawler <- mds(LawlerD, type = "interval")
jackfit <- jackknife(fit.lawler)
jackfit
plot(jackfit)
?jackknife
jackfit <- jackknife(fit.rock)
#############################
# Ratio unfolding
res <- unfolding(breakfast)
res
breakfast
breakfast$toast
breakfast$cornmuff
## various configuration plots
plot(res)
plot(res, type = "p", pch = 25)
plot(res, type = "p", pch = 25, col.columns = 3,
label.conf.columns = list(label = TRUE, pos = 3, col = 3),
col.rows = 8, label.conf.rows = list(label = TRUE, pos = 3, col = 8))
## Shepard plot
plot(res, "Shepard")
## Stress decomposition chart
plot(res, "stressplot")
res
## Stress decomposition chart
plot(res, "stressplot")
## Not run:
## Ordinal unfolding row conditional
## Note that ordinal unfolding may need many iterations (several thousands)
res <- unfolding(breakfast, type = "ordinal", conditionality = "row", omega = 0.1, itmax = 3000)
## Not run:
## Ordinal unfolding row conditional
## Note that ordinal unfolding may need many iterations (several thousands)
res <- unfolding(breakfast, type = "ordinal", conditionality = "row", omega = 0.1, itmax = 5000)
## Not run:
## Ordinal unfolding row conditional
## Note that ordinal unfolding may need many iterations (several thousands)
res <- unfolding(breakfast, type = "ordinal", conditionality = "row", omega = 0.1, itmax = 10000)
res
## Shepard plot
plot(res, "Shepard")
plot(res)
## Not run:
## Ordinal unfolding row conditional
## Note that ordinal unfolding may need many iterations (several thousands)
res <- unfolding(breakfast, type = "ordinal", omega = 0.1, itmax = 10000)
res
## Shepard plot
plot(res, "Shepard")
plot(res)
## Not run:
## Ordinal unfolding row conditional
## Note that ordinal unfolding may need many iterations (several thousands)
res <- unfolding(breakfast, type = "ordinal", conditionality = "col", omega = 0.1, itmax = 10000)
## Not run:
## Ordinal unfolding row conditional
## Note that ordinal unfolding may need many iterations (several thousands)
res <- unfolding(breakfast, type = "ordinal", conditionality = "matrix", omega = 0.1, itmax = 10000)
res
## Shepard plot
plot(res, "Shepard")
plot(res)
## Not run:
## Ordinal unfolding row conditional
## Note that ordinal unfolding may need many iterations (several thousands)
res <- unfolding(breakfast, type = "ordinal", conditionality = "row", omega = 0.1, itmax = 10000)
res
## Shepard plot
plot(res, "Shepard")
plot(res)
res
## Shepard plot
plot(res, "Shepard")
plot(res)
## Shepard plot
plot(res, "Shepard")
plot(res)
plot(res, "stressplot")
plot(res)
## Not run:
## Ordinal unfolding row conditional
## Note that ordinal unfolding may need many iterations (several thousands)
res <- unfolding(breakfast, type = "ordinal", conditionality = "row", omega = 0.1, itmax = 10000, circle='row')
## Not run:
## Ordinal unfolding row conditional
## Note that ordinal unfolding may need many iterations (several thousands)
res <- unfolding(breakfast, type = "ordinal", conditionality = "row", omega = 0.1, itmax = 10000, circle='column')
citation('smacof')
shiny::runApp('/srv/shiny-server/sample-apps/CONOCER')
shiny::runApp('/srv/shiny-server/sample-apps/CONOCER')
runApp('/srv/shiny-server/sample-apps/CONOCER')
runApp('/srv/shiny-server/sample-apps/CONOCER')
gc()
plot(c(0,0))
simula.init <- function(n.mas, n.menos, n.test, d)
{
#CLOSURE para simular obetner el errror de clasificaci贸n de MDP
#esta funcion regresa una funcion
#fijamos los parametros y la muestra
n.mas <- n.mas
n.menos <- n.menos
n.test <- n.test
d <- d
I <- diag(d)
n <- n.mas + n.menos
pos1 <- mvrnorm(n = n.mas, mu =c(2.2, rep(0, d-1) ), Sigma = diag(rep(1,d)))
pos1 <- as.data.frame(pos1)
neg1 <- mvrnorm(n = n.menos, mu =c(-2.2, rep(0, d-1) ), Sigma = diag(rep(1,d)))
neg1 <- as.data.frame(neg1)
train <- rbind(pos1,neg1)
train$label <- 1
train$label[(n.mas+1):(2*n.mas)] <- -1
library(MASS)
function(i)
{
#########genracion de conjunto test
test.1 <- mvrnorm(n = n.test/2, mu =c(2.2, rep(0, d-1) ), Sigma = diag(rep(1,d)))
test.1 <- as.data.frame(test.1)
test.1$label <- 1
test.2 <- mvrnorm(n = n.test/2, mu =c(-2.2, rep(0, d-1) ), Sigma = diag(rep(1,d)))
test.2 <- as.data.frame(test.2)
test.2$label <- -1
test <- rbind(test.1, test.2)
##############evaluacion de MDP
pos.mean <- apply(pos1, 2, mean)
neg.mean <- apply(neg1, 2, mean)
X <- ginv(cov(train[,  - (d+1)])) %*% (pos.mean - neg.mean)
MDP <- X/sum(X**2)**.5 #normalizamos el vector
test.predic <- as.matrix(test[, 1:d])%*%MDP
test$y_hat <-  ifelse(test.predic>=0, 1, -1)
error.MDP <- 1-sum(diag(table(test$label, test$y_hat)))/n.test
res <- c(error.MDP, i, d)
names(res) <- c('error.MDP', 'corrida','dimension')
return(res)
}
}
#save.image('data2.Rdata')
############ primera simulacion datos normales
set.seed(0)#semilla fuera de las funciones de simulacion
simula.init <- function(n.mas, n.menos, n.test, d)
{
#CLOSURE para simular obetner el errror de clasificaci贸n de MDP
#esta funcion regresa una funcion
#fijamos los parametros y la muestra
n.mas <- n.mas
n.menos <- n.menos
n.test <- n.test
d <- d
I <- diag(d)
n <- n.mas + n.menos
pos1 <- mvrnorm(n = n.mas, mu =c(2.2, rep(0, d-1) ), Sigma = diag(rep(1,d)))
pos1 <- as.data.frame(pos1)
neg1 <- mvrnorm(n = n.menos, mu =c(-2.2, rep(0, d-1) ), Sigma = diag(rep(1,d)))
neg1 <- as.data.frame(neg1)
train <- rbind(pos1,neg1)
train$label <- 1
train$label[(n.mas+1):(2*n.mas)] <- -1
library(MASS)
function(i)
{
#########genracion de conjunto test
test.1 <- mvrnorm(n = n.test/2, mu =c(2.2, rep(0, d-1) ), Sigma = diag(rep(1,d)))
test.1 <- as.data.frame(test.1)
test.1$label <- 1
test.2 <- mvrnorm(n = n.test/2, mu =c(-2.2, rep(0, d-1) ), Sigma = diag(rep(1,d)))
test.2 <- as.data.frame(test.2)
test.2$label <- -1
test <- rbind(test.1, test.2)
##############evaluacion de MDP
pos.mean <- apply(pos1, 2, mean)
neg.mean <- apply(neg1, 2, mean)
X <- ginv(cov(train[,  - (d+1)])) %*% (pos.mean - neg.mean)
MDP <- X/sum(X**2)**.5 #normalizamos el vector
test.predic <- as.matrix(test[, 1:d])%*%MDP
test$y_hat <-  ifelse(test.predic>=0, 1, -1)
error.MDP <- 1-sum(diag(table(test$label, test$y_hat)))/n.test
res <- c(error.MDP, i, d)
names(res) <- c('error.MDP', 'corrida','dimension')
return(res)
}
}
t1 <- Sys.time()
simula10 <- simula.init(n.mas = 25, n.menos=25, n.test =200, d=1600 )
MASS::mvrnorm()
?MASS::mvrnorm
#save.image('data2.Rdata')
############ primera simulacion datos normales
set.seed(0)#semilla fuera de las funciones de simulacion
simula.init <- function(n.mas, n.menos, n.test, d)
{
library(MASS)
#CLOSURE para simular obetner el errror de clasificaci贸n de MDP
#esta funcion regresa una funcion
#fijamos los parametros y la muestra
n.mas <- n.mas
n.menos <- n.menos
n.test <- n.test
d <- d
I <- diag(d)
n <- n.mas + n.menos
pos1 <- mvrnorm(n = n.mas, mu =c(2.2, rep(0, d-1) ), Sigma = diag(rep(1,d)))
pos1 <- as.data.frame(pos1)
neg1 <- mvrnorm(n = n.menos, mu =c(-2.2, rep(0, d-1) ), Sigma = diag(rep(1,d)))
neg1 <- as.data.frame(neg1)
train <- rbind(pos1,neg1)
train$label <- 1
train$label[(n.mas+1):(2*n.mas)] <- -1
function(i)
{
library(MASS)
#########genracion de conjunto test
test.1 <- mvrnorm(n = n.test/2, mu =c(2.2, rep(0, d-1) ), Sigma = diag(rep(1,d)))
test.1 <- as.data.frame(test.1)
test.1$label <- 1
test.2 <- mvrnorm(n = n.test/2, mu =c(-2.2, rep(0, d-1) ), Sigma = diag(rep(1,d)))
test.2 <- as.data.frame(test.2)
test.2$label <- -1
test <- rbind(test.1, test.2)
##############evaluacion de MDP
pos.mean <- apply(pos1, 2, mean)
neg.mean <- apply(neg1, 2, mean)
X <- ginv(cov(train[,  - (d+1)])) %*% (pos.mean - neg.mean)
MDP <- X/sum(X**2)**.5 #normalizamos el vector
test.predic <- as.matrix(test[, 1:d])%*%MDP
test$y_hat <-  ifelse(test.predic>=0, 1, -1)
error.MDP <- 1-sum(diag(table(test$label, test$y_hat)))/n.test
####################evaluacion de RLR
library(glmnet)
RLR <- glmnet(x = as.matrix(train[,1:d]), y = factor(train$label) , family = "binomial")
#plot(RLR)
y.RLR <- predict(RLR, newx = as.matrix(test[, 1:d]), type = "class", s =c(0.01)) #el paper dice que usaron este valor de lambda
e <- table( y.RLR, test$label)
error.RLR <- sum(diag(e))/n.test
res <- c(error.MDP, i, d, error.RLR)
names(res) <- c('MDP', 'corrida','dimension', 'RLR')
gc()
return(res)
}
}
t1 <- Sys.time()
t1 <- Sys.time()
simula10 <- simula.init(n.mas = 25, n.menos=25, n.test =200, d=100 )
library(parallel)
simulacion.10 <- mcmapply( FUN=simula10, 1:100, mc.cores = 6 )
simulacion.10 <- as.data.frame(t(simulacion.10))
t1 <- Sys.time() - t1
t1 #tiempo hasta 1600 solo para MDP con 100
t1 <- Sys.time()
simula10 <- simula.init(n.mas = 25, n.menos=25, n.test =200, d=400 )
library(parallel)
simulacion.10 <- mcmapply( FUN=simula10, 1:100, mc.cores = 6 )
simulacion.10 <- as.data.frame(t(simulacion.10))
t1 <- Sys.time() - t1
t1 #tiempo hasta 1600 solo para MDP con 100
t1 <- Sys.time()
simula10 <- simula.init(n.mas = 25, n.menos=25, n.test =200, d=100 )
library(parallel)
simulacion.10 <- mcmapply( FUN=simula10, 1:100, mc.cores = 1 )
simulacion.10 <- as.data.frame(t(simulacion.10))
t1 <- Sys.time() - t1
t1 #tiempo hasta 1600 solo para MDP con 100
t1 <- Sys.time()
simula10 <- simula.init(n.mas = 25, n.menos=25, n.test =200, d=100 )
library(parallel)
simulacion.10 <- mapply( FUN=simula10, 1:100 )
simulacion.10 <- as.data.frame(t(simulacion.10))
t1 <- Sys.time() - t1
t1 #tiempo hasta 1600 solo para MDP con 100
#save.image('data2.Rdata')
############ primera simulacion datos normales
set.seed(0)#semilla fuera de las funciones de simulacion
simula.init <- function(n.mas, n.menos, n.test, d)
{
library(MASS)
#CLOSURE para simular obetner el errror de clasificaci贸n de MDP
#esta funcion regresa una funcion
#fijamos los parametros y la muestra
n.mas <- n.mas
n.menos <- n.menos
n.test <- n.test
d <- d
I <- diag(d)
n <- n.mas + n.menos
pos1 <- mvrnorm(n = n.mas, mu =c(2.2, rep(0, d-1) ), Sigma = diag(rep(1,d)))
pos1 <- as.data.frame(pos1)
neg1 <- mvrnorm(n = n.menos, mu =c(-2.2, rep(0, d-1) ), Sigma = diag(rep(1,d)))
neg1 <- as.data.frame(neg1)
train <- rbind(pos1,neg1)
train$label <- 1
train$label[(n.mas+1):(2*n.mas)] <- -1
function(i)
{
library(MASS)
#########genracion de conjunto test
test.1 <- mvrnorm(n = n.test/2, mu =c(2.2, rep(0, d-1) ), Sigma = diag(rep(1,d)))
test.1 <- as.data.frame(test.1)
test.1$label <- 1
test.2 <- mvrnorm(n = n.test/2, mu =c(-2.2, rep(0, d-1) ), Sigma = diag(rep(1,d)))
test.2 <- as.data.frame(test.2)
test.2$label <- -1
test <- rbind(test.1, test.2)
##############evaluacion de MDP
pos.mean <- apply(pos1, 2, mean)
neg.mean <- apply(neg1, 2, mean)
X <- ginv(cov(train[,  - (d+1)])) %*% (pos.mean - neg.mean)
MDP <- X/sum(X**2)**.5 #normalizamos el vector
test.predic <- as.matrix(test[, 1:d])%*%MDP
test$y_hat <-  ifelse(test.predic>=0, 1, -1)
error.MDP <- 1-sum(diag(table(test$label, test$y_hat)))/n.test
####################evaluacion de RLR
library(glmnet)
RLR <- glmnet(x = as.matrix(train[,1:d]), y = factor(train$label) , family = "binomial")
#plot(RLR)
y.RLR <- predict(RLR, newx = as.matrix(test[, 1:d]), type = "class", s =c(0.01)) #el paper dice que usaron este valor de lambda
e <- table( y.RLR, test$label)
error.RLR <- sum(diag(e))/n.test
res <- c(error.MDP, i, d, error.RLR)
names(res) <- c('MDP', 'corrida','dimension', 'RLR')
gc()
return(res)
}
}
simula10 <- simula.init(n.mas = 25, n.menos=25, n.test =200, d=400 )
library(parallel)
simulacion.10 <- mapply( FUN=simula10, 1:100 )
simulacion.10 <- as.data.frame(t(simulacion.10))
t1 <- Sys.time() - t1
t1 #tiempo hasta 1600 solo para MDP con 100
t1 <- Sys.time()
simula10 <- simula.init(n.mas = 25, n.menos=25, n.test =200, d=400 )
library(parallel)
simulacion.10 <- mapply( FUN=simula10, 1:100 )
simulacion.10 <- as.data.frame(t(simulacion.10))
t1 <- Sys.time() - t1
t1 #tiempo hasta 1600 solo para MDP con 100
25*100/80
25/32
25/31
25*.8
200*.8
########################################################
####################### datos genes
setwd('/home/fou/Desktop/MCE/Second/CienciaDeDatos/DWD1')
dir()
genes <- read.csv('/home/fou/Desktop/TCGA-PANCAN-HiSeq-801x20531/data.csv', header = TRUE)
head(genes$X)
tail(genes$X)
grid <- seq(0.3162278, 31, length =5  )
grid <- grid**2
grid <- grid**2
grid <- grid**2
cancer$X <- NULL
genes$X <- NULL
y <- read.csv('/home/fou/Desktop/TCGA-PANCAN-HiSeq-801x20531/labels.csv', header = TRUE)
View(y)
table(y$Class)
datos <- c('COAD', 'LUAD') %in% y$Class
datos <-  y$Class %*% c('COAD', 'LUAD')
datos <-  y$Class %in% c('COAD', 'LUAD')
datos <- genes[datos, ]
write.csv(datos, 'subgenes.csv')
y$Class[datos]
y$Class
#genes <- read.csv('/home/fou/Desktop/TCGA-PANCAN-HiSeq-801x20531/data.csv', header = TRUE)
#grid <- seq(0.3162278, 31, length =5  )
#grid <- grid**2
#genes$X <- NULL
#y <- read.csv('/home/fou/Desktop/TCGA-PANCAN-HiSeq-801x20531/labels.csv', header = TRUE)
#table(y$Class)
datos <-  y$Class %in% c('COAD', 'LUAD')
y$Class[datos]
write.csv(y$Class[datos], 'sub_y.csv')
